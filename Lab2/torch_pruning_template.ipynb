{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdC9V9xB10Gt"
      },
      "source": [
        "# **Template for Torch-Pruning**\n",
        "\n",
        "This template is just built for your convinience.\n",
        "\n",
        "You are not required to follow the steps and method given below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jfw5rNimfwu",
        "outputId": "b5464a44-1f8b-4a2a-9a02-5ace83b35c3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch_pruning\n",
            "  Downloading torch_pruning-1.3.7-py3-none-any.whl (56 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/56.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torch_pruning) (2.2.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_pruning) (1.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torch_pruning) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->torch_pruning) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torch_pruning) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torch_pruning) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torch_pruning) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torch_pruning) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->torch_pruning)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->torch_pruning)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->torch_pruning)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch->torch_pruning)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch->torch_pruning)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.4/410.6 MB\u001b[0m \u001b[31m127.8 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade torch_pruning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-LiF8Vrqm2FU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.models import mobilenet_v2\n",
        "import torch_pruning as tp\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import copy\n",
        "from matplotlib import pyplot as plt\n",
        "from torch.optim import *\n",
        "from torch.optim.lr_scheduler import *\n",
        "from torch.utils.data import DataLoader\n",
        "from torchprofile import profile_macs\n",
        "from torchvision.datasets import *\n",
        "from torchvision.transforms import *\n",
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQ411pYQhkw4"
      },
      "source": [
        "##A Minimal Example ##  \n",
        "In this section, you will perform channel pruning using the library [Torch-Pruning](https://github.com/VainF/Torch-Pruning).  \n",
        "\n",
        "The puuner in Torch-Pruning has three main functions: sparse training (optional), importance estimation, and parameter removal.  \n",
        "Torch-pruning offers two core features to support this process:\n",
        "\n",
        "tp.importance(): This criteria is utilized to measure the importance of weights.  \n",
        "\n",
        "tp.pruner(): This is a pruner used for the actual pruning of the parameters.  \n",
        "\n",
        "For detailed information on this process, please refer to this [tutorial](https://github.com/VainF/Torch-Pruning/wiki/4.-High%E2%80%90level-Pruners/). Additionally, a more practical example is available in [here](https://github.com/VainF/Torch-Pruning/blob/master/benchmarks/main.py)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9e8CpBhmph9"
      },
      "source": [
        "### 1. Load model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "umaWm4eYms6G"
      },
      "outputs": [],
      "source": [
        "model = torch.load('./mobilenetv2_0.963.pth', map_location=\"cpu\")\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "def recover_model():\n",
        "  from torchvision.models import mobilenet_v2, MobileNet_V2_Weights\n",
        "  model = mobilenet_v2()\n",
        "\n",
        "  NUM_CLASSES=10\n",
        "  model.classifier[1] = nn.Linear(model.classifier[1].in_features, NUM_CLASSES)\n",
        "  model = torch.load(\"mobilenetv2_0.963.pth\")\n",
        "  model.cuda()\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSe6NDqqm_qN"
      },
      "source": [
        "### 2. Prepare a pruner\n",
        "By default, Torch-Pruning will automatically prune the last non-singleton dim of these parameters. If you want to customize this behaviour, please provide an `unwrapped_parameters` list as the following example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(\n",
        "  model: nn.Module,\n",
        "  dataloader: DataLoader,\n",
        "  criterion: nn.Module,\n",
        "  optimizer: Optimizer,\n",
        "  scheduler: LambdaLR,\n",
        "  callbacks = None\n",
        ") -> None:\n",
        "  model.train()\n",
        "\n",
        "  for inputs, targets in tqdm(dataloader, desc='train', leave=False):\n",
        "    # Move the data from CPU to GPU\n",
        "    inputs = inputs.cuda()\n",
        "    targets = targets.cuda()\n",
        "\n",
        "    # Reset the gradients (from the last iteration)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward inference\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, targets)\n",
        "\n",
        "    # Backward propagation\n",
        "    loss.backward()\n",
        "\n",
        "    # Update optimizer and LR scheduler\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "\n",
        "    if callbacks is not None:\n",
        "        for callback in callbacks:\n",
        "            callback()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "@torch.inference_mode()\n",
        "def evaluate(\n",
        "  model: nn.Module,\n",
        "  dataloader: DataLoader,\n",
        "  verbose=True,\n",
        ") -> float:\n",
        "  model.eval()\n",
        "\n",
        "  num_samples = 0\n",
        "  num_correct = 0\n",
        "\n",
        "  for inputs, targets in tqdm(dataloader, desc=\"eval\", leave=False,\n",
        "                              disable=not verbose):\n",
        "    # Move the data from CPU to GPU\n",
        "    inputs = inputs.cuda()\n",
        "    targets = targets.cuda()\n",
        "\n",
        "    # Inference\n",
        "    outputs = model(inputs)\n",
        "\n",
        "    # Convert logits to class indices\n",
        "    outputs = outputs.argmax(dim=1)\n",
        "\n",
        "    # Update metrics\n",
        "    num_samples += targets.size(0)\n",
        "    num_correct += (outputs == targets).sum()\n",
        "\n",
        "  return (num_correct / num_samples * 100).item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "transforms = {\n",
        "    \"train\": Compose([\n",
        "      Resize((224, 224)),\n",
        "      ToTensor(),\n",
        "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    \"test\": Compose([\n",
        "      Resize((224, 224)),\n",
        "      ToTensor(),\n",
        "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "dataset = {}\n",
        "for split in [\"train\", \"test\"]:\n",
        "  dataset[split] = CIFAR10(\n",
        "    root=\"data/cifar10\",\n",
        "    train=(split == \"train\"),\n",
        "    download=True,\n",
        "    transform=transforms[split],\n",
        "  )\n",
        "\n",
        "# You can apply your own batch_size\n",
        "dataloader = {}\n",
        "for split in ['train', 'test']:\n",
        "  dataloader[split] = DataLoader(\n",
        "    dataset[split],\n",
        "    batch_size=64,\n",
        "    shuffle=(split == 'train'),\n",
        "    num_workers=0,\n",
        "    pin_memory=True,\n",
        "    drop_last=True\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = recover_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [],
      "source": [
        "sparsity_dict = {\n",
        "##################### YOUR CODE STARTS HERE #####################\n",
        "    # please modify the sparsity value of each layer\n",
        "    # please DO NOT modify the key of sparsity_dict\n",
        "    model.features[0][0] : 0,\n",
        "    model.features[1].conv[0][0]: 0,\n",
        "    model.features[1].conv[1]: 0,\n",
        "    model.features[2].conv[0][0]: 0,\n",
        "    model.features[2].conv[1][0]: 0,\n",
        "    model.features[2].conv[2]: 0,\n",
        "    model.features[3].conv[0][0]: 0,\n",
        "    model.features[3].conv[1][0]: 0,\n",
        "    model.features[3].conv[2]: 0,\n",
        "    model.features[4].conv[0][0]: 0,\n",
        "    model.features[4].conv[1][0]: 0,\n",
        "    model.features[4].conv[2]: 0,\n",
        "    model.features[5].conv[0][0]: 0,\n",
        "    model.features[5].conv[1][0]: 0,\n",
        "    model.features[5].conv[2]: 0,\n",
        "    model.features[6].conv[0][0]: 0,\n",
        "    model.features[6].conv[1][0]: 0,\n",
        "    model.features[6].conv[2]: 0,\n",
        "    model.features[7].conv[0][0]: 0,\n",
        "    model.features[7].conv[1][0]: 0,\n",
        "    model.features[7].conv[2]: 0,\n",
        "    model.features[8].conv[0][0]: 0,\n",
        "    model.features[8].conv[1][0]: 0,\n",
        "    model.features[8].conv[2]: 0,\n",
        "    model.features[9].conv[0][0]: 0,\n",
        "    model.features[9].conv[1][0]: 0,\n",
        "    model.features[9].conv[2]: 0.3,\n",
        "    model.features[10].conv[0][0]: 0.3,\n",
        "    model.features[10].conv[1][0]: 0,\n",
        "    model.features[10].conv[2]: 0.3,\n",
        "    model.features[11].conv[0][0]: 0.3,\n",
        "    model.features[11].conv[1][0]: 0,\n",
        "    model.features[11].conv[2]: 0.3,\n",
        "    model.features[12].conv[0][0]: 0.3,\n",
        "    model.features[12].conv[1][0]: 0,\n",
        "    model.features[12].conv[2]: 0.3,\n",
        "    model.features[13].conv[0][0]: 0.3,\n",
        "    model.features[13].conv[1][0]: 0,\n",
        "    model.features[13].conv[2]: 0.3,\n",
        "    model.features[14].conv[0][0]: 0.3,\n",
        "    model.features[14].conv[1][0]: 0,\n",
        "    model.features[14].conv[2]: 0.15,\n",
        "    model.features[15].conv[0][0]: 0.15,\n",
        "    model.features[15].conv[1][0]: 0,\n",
        "    model.features[15].conv[2]: 0.15,\n",
        "    model.features[16].conv[0][0]: 0.15,\n",
        "    model.features[16].conv[1][0]: 0,\n",
        "    model.features[16].conv[2]: 0.15,\n",
        "    model.features[17].conv[0][0]: 0.15,\n",
        "    model.features[17].conv[1][0]: 0,\n",
        "    model.features[17].conv[2]: 0.05,\n",
        "    model.features[18][0]: 0.05,\n",
        "    model.classifier[1]: 0\n",
        "##################### YOUR CODE ENDS HERE #######################\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get the number of group in conv2d or group norm layer in the model\n",
        "def get_group_num(model):\n",
        "    group = {}\n",
        "    for name, module in model.named_modules():\n",
        "        if isinstance(module, (nn.Conv2d, nn.GroupNorm)) and module.groups > 1:\n",
        "            group[name] = module.groups\n",
        "    return group\n",
        "channel_groups = get_group_num(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importance criterion\n",
        "imp = tp.importance.GroupNormImportance(p=1) # or GroupTaylorImportance(), GroupHessianImportance(), etc.\n",
        "\n",
        "# Initialize a pruner with the model and the importance criterion\n",
        "example_inputs = torch.randn(1, 3, 224, 224).to(device)\n",
        "\n",
        "ignored_layers = []\n",
        "for m in model.modules():\n",
        "  if isinstance(m, torch.nn.Linear) and m.out_features == 10: # ignore the classifier\n",
        "    ignored_layers.append(m)\n",
        "pruner = tp.pruner.GroupNormPruner ( # you can choose any pruner you like.\n",
        "    model,\n",
        "    example_inputs,\n",
        "    importance=imp,   # Importance Estimator\n",
        "    global_pruning=False,\n",
        "    pruning_ratio=0.6, # remove 50% channels, ex :ResNet18 = {64, 128, 256, 512} => ResNet18_Half = {32, 64, 128, 256}\n",
        "    iterative_steps = 1,  # number of steps to achieve the target ch_sparsity.\n",
        "    ignored_layers = ignored_layers,        # ignore some layers such as the finall linear classifier\n",
        "    channel_groups = channel_groups,  # round channels\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1XmDH9ToKYO"
      },
      "source": [
        "### 3. Prune the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "qmklPY2goMX2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The pruned model:\n",
            "MobileNetV2(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2dNormActivation(\n",
            "      (0): Conv2d(3, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU6(inplace=True)\n",
            "    )\n",
            "    (1): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
            "          (1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2d(12, 6, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (2): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (2): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(6, 38, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(38, 38, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=38, bias=False)\n",
            "          (1): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(38, 9, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (3): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(9, 57, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(57, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(57, 57, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=57, bias=False)\n",
            "          (1): BatchNorm2d(57, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(57, 9, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (4): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(9, 57, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(57, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(57, 57, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=57, bias=False)\n",
            "          (1): BatchNorm2d(57, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(57, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (5): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(12, 76, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(76, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(76, 76, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=76, bias=False)\n",
            "          (1): BatchNorm2d(76, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(76, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (6): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(12, 76, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(76, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(76, 76, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=76, bias=False)\n",
            "          (1): BatchNorm2d(76, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(76, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (7): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(12, 76, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(76, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(76, 76, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=76, bias=False)\n",
            "          (1): BatchNorm2d(76, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(76, 25, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (8): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(25, 153, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(153, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(153, 153, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=153, bias=False)\n",
            "          (1): BatchNorm2d(153, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(153, 25, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (9): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(25, 153, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(153, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(153, 153, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=153, bias=False)\n",
            "          (1): BatchNorm2d(153, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(153, 25, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (10): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(25, 153, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(153, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(153, 153, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=153, bias=False)\n",
            "          (1): BatchNorm2d(153, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(153, 25, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (11): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(25, 153, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(153, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(153, 153, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=153, bias=False)\n",
            "          (1): BatchNorm2d(153, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(153, 38, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (12): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(38, 230, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(230, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(230, 230, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=230, bias=False)\n",
            "          (1): BatchNorm2d(230, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(230, 38, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (13): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(38, 230, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(230, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(230, 230, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=230, bias=False)\n",
            "          (1): BatchNorm2d(230, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(230, 38, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (14): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(38, 230, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(230, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(230, 230, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=230, bias=False)\n",
            "          (1): BatchNorm2d(230, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(230, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (15): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
            "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (16): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
            "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (17): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
            "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (18): Conv2dNormActivation(\n",
            "      (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU6(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.2, inplace=False)\n",
            "    (1): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Summary:\n",
            "MFLOPs: \n",
            "61.325886\n"
          ]
        }
      ],
      "source": [
        "# Model size before pruning\n",
        "base_macs, base_nparams = tp.utils.count_ops_and_params(model, torch.randn(1,3,224,224).cuda())\n",
        "\n",
        "model.eval()\n",
        "\n",
        "if isinstance(imp, tp.importance.GroupTaylorImportance):\n",
        "  # Taylor expansion requires gradients for importance estimation\n",
        "  loss = model(example_inputs).sum() # A dummy loss, please replace this line with your loss function and data!\n",
        "  loss.backward() # before pruner.step()\n",
        "\n",
        "# prune\n",
        "pruner.step()\n",
        "\n",
        "\n",
        "# Parameter & MACs Counter\n",
        "pruned_macs, pruned_nparams = tp.utils.count_ops_and_params(model, torch.randn(1,3,224,224).cuda())\n",
        "MFLOPs = pruned_macs/1e6\n",
        "print(\"The pruned model:\")\n",
        "print(model)\n",
        "print(\"Summary:\")\n",
        "print(\"MFLOPs: \")\n",
        "print(MFLOPs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d47cfebfc04a4de7ab1973900a57b110",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "eval:   0%|          | 0/156 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy before fine-tuning: 10.02%\n",
            "Finetuning Fine-grained Pruned Sparse Model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "939935f0c0ec464e83495b4fd93c46e6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train:   0%|          | 0/781 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "06343c8b935d4f65be22fd4fa97794e3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "eval:   0%|          | 0/156 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Epoch 1 Accuracy 65.09% / Best Accuracy: 65.09%\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f14b6e7e93274b2386ec4c7b69e17e47",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train:   0%|          | 0/781 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "704bfedb3874436d80a1bd6ef4c23755",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "eval:   0%|          | 0/156 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Epoch 2 Accuracy 74.55% / Best Accuracy: 74.55%\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e97c95a7a78b4eb2b49381dd41161cef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train:   0%|          | 0/781 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c14702969b8f4b4eb69eb36243e80517",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "eval:   0%|          | 0/156 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Epoch 3 Accuracy 79.96% / Best Accuracy: 79.96%\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3cb80dc6e3ed469db3b3304caeaa1727",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train:   0%|          | 0/781 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f7b2b49689f642d9a63bd24ce3a3c380",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "eval:   0%|          | 0/156 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Epoch 4 Accuracy 80.38% / Best Accuracy: 80.38%\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a6b92bca8bf46b5b4b8a7ab24ae7876",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train:   0%|          | 0/781 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7ba82dd27efe4917af08b5fde7a3b0d2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "eval:   0%|          | 0/156 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Epoch 5 Accuracy 80.92% / Best Accuracy: 80.92%\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ef3e75071b94361ad05e9bf388aef9c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train:   0%|          | 0/781 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "553f5c2b11a949cdba942df099b6e4be",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "eval:   0%|          | 0/156 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Epoch 6 Accuracy 82.42% / Best Accuracy: 82.42%\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ac2d81fb544047439074378898aa8a88",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train:   0%|          | 0/781 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f4fb5b48a08d4b848f51fc73319f5944",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "eval:   0%|          | 0/156 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Epoch 7 Accuracy 82.37% / Best Accuracy: 82.42%\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "180d12ccf4bc4183bd20c9ea4a5e4282",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train:   0%|          | 0/781 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "19b95bf3b0594c0e808b913052602b6c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "eval:   0%|          | 0/156 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Epoch 8 Accuracy 84.40% / Best Accuracy: 84.40%\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "18bf44a69d094610822dabd9e84c9e91",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train:   0%|          | 0/781 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7ea76b3453144673b39ec6bc075525bd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "eval:   0%|          | 0/156 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Epoch 9 Accuracy 85.97% / Best Accuracy: 85.97%\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "199bb2a5067b4a98a572c3723770e5ae",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train:   0%|          | 0/781 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c494cab9dd444fc4a7e8d53797443d0a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "eval:   0%|          | 0/156 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Epoch 10 Accuracy 84.61% / Best Accuracy: 85.97%\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3bad69b41e93448da3705b40a5605cdc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "eval:   0%|          | 0/156 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy after fine-tuning: 84.61%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "accuracy = evaluate(model, dataloader['test'])\n",
        "print(f\"Accuracy before fine-tuning: {accuracy:.2f}%\")\n",
        "\n",
        "# finetune the pruned model here\n",
        "# finetune(model)\n",
        "num_finetune_epochs = 10\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_finetune_epochs)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "best_sparse_model_checkpoint = dict()\n",
        "best_accuracy = 0\n",
        "print(f'Finetuning Fine-grained Pruned Sparse Model')\n",
        "for epoch in range(num_finetune_epochs):\n",
        "    # At the end of each train iteration, we have to apply the pruning mask\n",
        "    #    to keep the model sparse during the training\n",
        "    train(model, dataloader['train'], criterion, optimizer, scheduler)\n",
        "    accuracy = evaluate(model, dataloader['test'])\n",
        "    is_best = accuracy > best_accuracy\n",
        "    if is_best:\n",
        "        best_sparse_model_checkpoint['state_dict'] = copy.deepcopy(model.state_dict())\n",
        "        best_accuracy = accuracy\n",
        "    print(f'    Epoch {epoch+1} Accuracy {accuracy:.2f}% / Best Accuracy: {best_accuracy:.2f}%')\n",
        "\n",
        "# Parameter & MACs Counter\n",
        "accuracy = evaluate(model, dataloader['test'])\n",
        "print(f\"Accuracy after fine-tuning: {accuracy:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
